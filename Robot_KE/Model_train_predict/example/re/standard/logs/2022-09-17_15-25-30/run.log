[2022-09-17 15:25:30,448][__main__][INFO] - 
cwd: /home/zzx/remove_file/Model_train/example/re/standard
preprocess: true
data_path: data/origin
out_path: data/out
chinese_split: true
replace_entity_with_type: true
replace_entity_with_scope: true
min_freq: 3
pos_limit: 30
seed: 1
use_gpu: true
gpu_id: 0
epoch: 150
batch_size: 32
learning_rate: 0.0003
lr_factor: 0.7
lr_patience: 3
weight_decay: 0.001
early_stopping_patience: 6
train_log: true
log_interval: 10
show_plot: true
only_comparison_plot: false
plot_utils: matplot
predict_plot: false
vocab_size: ???
word_dim: 60
pos_size: 62
pos_dim: 10
dim_strategy: sum
num_relations: 15
fp: /home/zzx/deepke/DeepKE/example/re/standard/checkpoints/2022-09-10_17-22-56/lm_epoch150.pth
model_name: lm
lm_file: bert-base-chinese
num_hidden_layers: 1
type_rnn: LSTM
input_size: 768
hidden_size: 100
num_layers: 1
dropout: 0.3
bidirectional: true
last_layer_hn: true

[2022-09-17 15:25:34,915][__main__][INFO] - device: cuda:0
[2022-09-17 15:25:34,915][deepke.relation_extraction.standard.tools.preprocess][INFO] - ===== start preprocess data =====
[2022-09-17 15:25:34,915][deepke.relation_extraction.standard.tools.preprocess][INFO] - load raw files...
[2022-09-17 15:25:34,915][utils.ioUtils][INFO] - load csv from /home/zzx/remove_file/Model_train/example/re/standard/data/origin/train.csv
[2022-09-17 15:25:34,918][utils.ioUtils][INFO] - load csv from /home/zzx/remove_file/Model_train/example/re/standard/data/origin/valid.csv
[2022-09-17 15:25:34,918][utils.ioUtils][INFO] - load csv from /home/zzx/remove_file/Model_train/example/re/standard/data/origin/test.csv
[2022-09-17 15:25:34,919][utils.ioUtils][INFO] - load csv from /home/zzx/remove_file/Model_train/example/re/standard/data/origin/relation.csv
[2022-09-17 15:25:34,919][deepke.relation_extraction.standard.tools.preprocess][INFO] - clean data...
[2022-09-17 15:25:34,922][deepke.relation_extraction.standard.tools.preprocess][INFO] - convert relation into index...
[2022-09-17 15:25:34,923][deepke.relation_extraction.standard.tools.preprocess][INFO] - verify whether use pretrained language models...
[2022-09-17 15:25:34,923][deepke.relation_extraction.standard.tools.preprocess][INFO] - use pretrained language models serialize sentence...
[2022-09-17 15:25:34,923][deepke.relation_extraction.standard.tools.preprocess][INFO] - use bert tokenizer...
[2022-09-17 15:25:36,341][deepke.relation_extraction.standard.tools.preprocess][INFO] - use bert tokenizer...
[2022-09-17 15:25:37,400][deepke.relation_extraction.standard.tools.preprocess][INFO] - use bert tokenizer...
[2022-09-17 15:25:38,433][deepke.relation_extraction.standard.tools.preprocess][INFO] - save data for backup...
[2022-09-17 15:25:38,434][utils.ioUtils][INFO] - save data in /home/zzx/remove_file/Model_train/example/re/standard/data/out/train.pkl
[2022-09-17 15:25:38,436][utils.ioUtils][INFO] - save data in /home/zzx/remove_file/Model_train/example/re/standard/data/out/valid.pkl
[2022-09-17 15:25:38,437][utils.ioUtils][INFO] - save data in /home/zzx/remove_file/Model_train/example/re/standard/data/out/test.pkl
[2022-09-17 15:25:38,437][deepke.relation_extraction.standard.tools.preprocess][INFO] - ===== end preprocess data =====
[2022-09-17 15:25:38,438][utils.ioUtils][INFO] - load data from /home/zzx/remove_file/Model_train/example/re/standard/data/out/train.pkl
[2022-09-17 15:25:38,441][utils.ioUtils][INFO] - load data from /home/zzx/remove_file/Model_train/example/re/standard/data/out/valid.pkl
[2022-09-17 15:25:38,441][utils.ioUtils][INFO] - load data from /home/zzx/remove_file/Model_train/example/re/standard/data/out/test.pkl
[2022-09-17 15:25:43,500][__main__][INFO] - 
 LM(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(21128, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0): BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (bilstm): RNN(
    (rnn): LSTM(768, 50, batch_first=True, dropout=0.3, bidirectional=True)
  )
  (fc): Linear(in_features=100, out_features=15, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
)
[2022-09-17 15:25:43,501][__main__][INFO] - ========== Start training ==========
[2022-09-17 15:25:44,036][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 1: [320/577 (55%)]	Loss: 1.998968
[2022-09-17 15:25:44,036][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 1: Acc: 29.06%	macro metrics: [p: 0.1829, r:0.1465, f1:0.1279]
[2022-09-17 15:25:44,466][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 1: [577/577 (100%)]	Loss: 1.127360
[2022-09-17 15:25:44,466][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 1: Acc: 41.59%	macro metrics: [p: 0.3369, r:0.2375, f1:0.2384]
[2022-09-17 15:25:44,555][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 1: [93/93](100%)	 Loss: 1.499008
[2022-09-17 15:25:44,555][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 1: Acc: 61.29%	macro metrics: [p: 0.5978, r:0.5668, f1:0.5242]
[2022-09-17 15:25:45,277][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 2: [320/577 (55%)]	Loss: 1.238178
[2022-09-17 15:25:45,277][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 2: Acc: 75.94%	macro metrics: [p: 0.8635, r:0.6751, f1:0.6957]
[2022-09-17 15:25:45,744][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 2: [577/577 (100%)]	Loss: 1.011739
[2022-09-17 15:25:45,744][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 2: Acc: 80.76%	macro metrics: [p: 0.8628, r:0.7370, f1:0.7586]
[2022-09-17 15:25:45,809][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 2: [93/93](100%)	 Loss: 0.851101
[2022-09-17 15:25:45,809][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 2: Acc: 90.32%	macro metrics: [p: 0.8053, r:0.8229, f1:0.7881]
[2022-09-17 15:25:46,542][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 3: [320/577 (55%)]	Loss: 0.695126
[2022-09-17 15:25:46,542][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 3: Acc: 92.19%	macro metrics: [p: 0.9143, r:0.9061, f1:0.9034]
[2022-09-17 15:25:46,963][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 3: [577/577 (100%)]	Loss: 1.042730
[2022-09-17 15:25:46,963][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 3: Acc: 94.45%	macro metrics: [p: 0.9400, r:0.9330, f1:0.9328]
[2022-09-17 15:25:47,037][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 3: [93/93](100%)	 Loss: 0.528908
[2022-09-17 15:25:47,037][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 3: Acc: 91.40%	macro metrics: [p: 0.8125, r:0.8671, f1:0.8284]
[2022-09-17 15:25:47,795][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 4: [320/577 (55%)]	Loss: 0.369835
[2022-09-17 15:25:47,796][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 4: Acc: 97.81%	macro metrics: [p: 0.9711, r:0.9737, f1:0.9713]
[2022-09-17 15:25:48,228][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 4: [577/577 (100%)]	Loss: 0.172599
[2022-09-17 15:25:48,228][deepke.relation_extraction.standard.tools.trainer][INFO] - Train Epoch 4: Acc: 98.44%	macro metrics: [p: 0.9793, r:0.9824, f1:0.9806]
[2022-09-17 15:25:48,304][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 4: [93/93](100%)	 Loss: 0.413582
[2022-09-17 15:25:48,304][deepke.relation_extraction.standard.tools.trainer][INFO] - Valid Epoch 4: Acc: 91.40%	macro metrics: [p: 0.8000, r:0.8566, f1:0.8149]
